# 这是第三篇，有关python3编码

### 缘由

今天逛知乎，因为之前有关注python话题，今儿看到一片[推送](https://zhuanlan.zhihu.com/p/40834093),讲的是有关python的编码问题，想起最近处理数据时也会偶尔遇见这种问题，虽然知道改一下encoding就可以解决问题，但一直没有从根本上了解python3的编码，既然你都给我推送了，那我就勉为其难的看一下好了，hhhh，这里吐嘈一下知乎的网页版，全是各种乱七八糟的推送，简直没法看，还是老老实实看app好了。

### 一些点

上面这篇知乎文章其实已经讲的足够好了，但是我看的时候还是有些地方有些费神，有些过程还是很不理解，最后又翻了好多网页，仔细把写代码、跑代码怎么流程过了一片，算是大致了解了整个过程吧，于是在这里做一个梳理，方便日后查阅。先说说我认为理解计算机编码得需要的一些前置知识吧。

- 编码字符集和字符集编码

  这里我觉得[这篇博客](http://www.blogjava.net/zhenandaci/archive/2008/12/24/248041.html)讲的很好，可以看看。

- unicode和utf、gbk

  unicode是『字符集』，什么是字符集呢，就是所有字符的合集啦，类似于『我』在unicode里就是『b\u6211』，每一个你能看见的字符在unicode里都有一个码位，我们这里把码位到字符取个名字好了，就叫它『映射』好了。这里『映射』既包括从码位到字符也包括字符到码位。unicode是存储格式是定长的，占用空间比较大，在电脑上存存没关系，还可以提高存取速度，可关系到传输什么的就不好了。于是有了utf, 因为utf-8是变长的，利于传输，所以**在计算机内存里，代码、运算什么的都是用的是unicode，而到了保存在磁盘、网络传输，都是用的utf-8.** 这句话很重要啊！『我』的utf-8编码便是『b'\xe6\x88\x91'』，这个是由上面的unicode码位来的，至于怎么来的，可以查看知乎的[这个问题](https://www.zhihu.com/question/23374078)，其实utf-8的也是可以将抽象字符和二进制编码一一对应的，但其中是通过unicode来转换的，就相当于unicode是厚厚的字典，而utf-8便是在索引上做了小小的改进。

  那gbk又是啥，gbk即是『字符集』，又是一种『编码规则』，但python里，因为内部都是采用unicode编码，你可以暂时理解gbk也是unicode的一种『编码规则』，可以将unicode的中英文符编码成二进制字节码。

- 解码和译码

  编码是『解码』和『译码』两个概念，编码对应的是encode、解码对应的是decode。编码的意思是把抽象字符（可以在unicode里直接『映射』的）通过utf-8、gbk等不同方式转换成对应的二进制字节码，而解码就是把那些二进制字节码转换成字符（也可以是b\uxxxx，因为可以通过『映射』可以找到相应的字符）。

- python2和python3

  python3默认的编码改成了utf-8,对比起python2默认ascii来说，其实中文编码已经不算那么坑了。python3字符属于str这个类，二进制字节码属于bytes这个类，由str2bytes用encode这个函数，bytes2str用decode这个函数。

- linux和win

  linux平台都是采用是utf-8，win平台是gbk编码，所以win推荐notepad++代替自带的编辑器啊。

### 跑代码

```python
s = '哈哈'
print(s)
print(s.encode('unicode_escape'))
print(s.encode('utf-8'))
print(s.encode('gbk'))
```

> 哈哈
>
> b'\\u54c8\\u54c8'
>
> b'\xe5\x93\x88\xe5\x93\x88'
>
> b'\xb9\xfe\xb9\xfe'

首先明确一点，在ipython里跑`s = '哈哈'`这里『哈哈』是存放在内存里，也就是的unicode编码『b'\\u54c8\\u54c8'』，ipython直接unicode『映射』打印出来也就是『哈哈』。而把内存里`0101010011001000`(54c8)按照不同的方式编码就会得到不同的二进制字节码。

```python
# -*- coding:gbk -*-
s = '哈哈'
print(s)
print(s.encode('unicode_escape'))
with open('utf', 'w', encoding = 'utf-8') as f:
    f.write(s)
with open('gbk', 'w', encoding = 'gbk') as f:
    f.write(s)
```

> 鍝堝搱
>
> b'\\u935d\\u581d\\u6431'
>
> cat utf -----> 鍝堝搱
>
> cat gbk----->哈哈

这里是一个py文件，写好之后python3运行，会发现打印出的是乱码，篇头那篇知乎专栏已经写的很好了，因为在代码头加的`# -*- coding:gbk -*-` 就是告诉python3以何种方式去『译码』这个文件，由于你写代码的编辑器应该不是win自带的记事本，应该是utf-8的编辑器，就是说这个编辑器是以utf-8『编码』这个文件保存到磁盘里的。当python3以gbk『译码』这个文件成unicode时，英文字符不影响，因为gbk和utf-8英文字符是兼容的，而中文字符你以unicode--->utf-8『编码』再当把utf-8---->unicode时以gbk『译码』，得到的unicode在『映射』成字符，肯定不是原来的味道了啊，于是得到了喜闻乐见的乱码『鍝堝搱』。

在看看下面的两个文件utf和gbk，在写完代码后存盘发生的事情是『b'\\u54c8\\u54c8'』--->『b'\xe5\x93\x88\xe5\x93\x88'』，utf-8编码。之后用python3运行时，发生的事情是『b'\xe5\x93\x88\xe5\x93\x88'』--->『b'\\u935d\\u581d\\u6431'』，gbk译码。放到内存中，在运行第一个with代码段时，『b'\\u935d\\u581d\\u6431'』--->『b'\xe9\x8d\x9d\xe5\xa0\x9d\xe6\x90\xb1'』，utf-8编码。当运行第二个代码段时，『b'\\u935d\\u581d\\u6431'--->『b'\xe5\x93\x88\xe5\x93\x88'』，gbk编码。

你在用cat utf命令运行时，文件被放到内存里，此时『b'\xe9\x8d\x9d\xe5\xa0\x9d\xe6\x90\xb1'』--->『b'\\u935d\\u581d\\u6431'』，utf-8译码，再经过『映射』，得到『鍝堝搱』显示在屏幕上。

你在用cat gbk命令运行时，文件被放到内存里，此时『b'\xe5\x93\x88\xe5\x93\x88'』--->『b'\\u54c8\\u54c8'』，utf-8译码，再经过『映射』，得到『哈哈』显示在屏幕上。

```python
with open('utf', 'w', encoding = 'utf-8') as f:
    f.write('哈哈')
with open('utf', 'r', encoding = 'utf-8') as f:
    s = f.readline()
```

对于第一个with代码段而言，我是以utf-8的方式去『编码』utf这个文件，而对于第二个with代码段而言，我是以utf-8的方式去『译码』utf这个文件，所以虽然是同一个函数的相同参数，但它看文件的角度发生了变化，反正但是这么点小问题让我想了一久，如果觉得很弱智，就跳过好啦。

### 总结

把握python3中str和bytes两个类，用相同的编码格式再用相同的格式去译码，应该能解决大部分问题，需要了解的是py文件头的编码注释是写给python3编译器去看的，这决定了磁盘的文件是以何种格式『译码』成unicode的。之前也是被这个问题困扰很久，这篇也反反复复写了快一天才觉得好像差不多，这一天也是查各种博客和专栏，也没有查更权威的资料，很多也都是我自己个人的理解，所以细节有误甚至整个思路都是错的也是可能的，如果告知，感激不尽。



